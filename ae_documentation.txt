GPU Evaluation
* Environment:
** Host (Google cloud n1-standard-8)
*** Hardware: Intel(R) Xeon(R) CPU @ 2.30GHz, Nvidia Tesla V100 SXM2 16GB
*** Software: Ubuntu 20.04, Nvidia driver version: 460.91.03, docker version 20.10.8

** Docker container
*** Software: Ubuntu 20.04, CUDA 11.1 (V11.1.105), cuDNN 8.2.1, PyTorch 1.9.0+cu111, FasterTransformer (modified on top of FasterTransformer v4.0 (commit dd4c071))
    - Make sure that nvcc is on the PATH
*** CoRa's dependencies: Z3 4.8.8.0, LLVM 9.0.0, cmake >= 3.5, G++ >= 5.0

* Setting up CoRa
  1. Set up dependencies
     a. CoRa is built on top of TVM, which requires the following dependencies: numpy, pytest, attrs, decorator, scipy.
     b. Building CoRa also requires CUDA and Z3 to be discoverable by cmake i.e. installed in standard locations.
     c. One can download a prebuilt copy of LLVM-9.0.0 from the LLVM download page (https://releases.llvm.org/download.html). the pre-built version for Ubuntu 18.04 should work.

  1. Clone the repo: https://github.com/pratikfegade/incubator-tvm, and switch to the ragged_tensors branch
  2. In the repo, create a build folder, and copy the file incubator-tvm/config.cmake to the build folder
  4. Update the variable USE_LLVM to point to the llvm-config binary in the downloaded llvm version.
  3. Compile CoRa, either using make, or ninja:
     a. Compile using make: In the build folder, run `cmake ..; make -j8 tvm`
     b. Compile using ninja: In the build folder, run `cmake -G Ninja ..; ninja tvm`
     Building CoRa should generate a shared file called libtvm.so in the build folder
  4. Set your PYTHONPATH to include the python incubator-tvm/python directory.

* All paths below are relative to the root of the benchmarks repository

- Section 7.2: The Transformer Model

-- Table 5: MHA evaluation on ARM CPU

- Sections 7.3 and D.6: Operation Splitting and Horizontal Fusion (AttnV in Section 7.3 and QKt in Section D.6)
  1. Run python3 scripts/bin_packed_eval.py --target cuda --stdout --max-batches 50. Output will be generated in results/bin_packed_results_cuda.csv.
